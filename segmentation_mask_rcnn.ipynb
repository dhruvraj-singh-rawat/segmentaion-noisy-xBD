{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 00:59:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 00:59:47 d2.data.datasets.coco]: \u001b[0mLoaded 5690 images in COCO format from train_output_coco_annotations.json\n",
      "\u001b[32m[09/09 00:59:47 d2.data.build]: \u001b[0mRemoved 4198 images with no usable annotations. 1492 images left.\n",
      "\u001b[32m[09/09 00:59:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   damage   | 32467        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[09/09 00:59:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/09 00:59:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/09 00:59:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/09 00:59:47 d2.data.common]: \u001b[0mSerializing 1492 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 00:59:47 d2.data.common]: \u001b[0mSerialized dataset takes 10.33 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 00:59:47 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[09/09 00:59:47 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 00:59:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvraj/venv-metal/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 01:01:07 d2.utils.events]: \u001b[0m eta: 1:09:32  iter: 19  total_loss: 4.188  loss_cls: 0.7786  loss_box_reg: 0.261  loss_mask: 0.6933  loss_rpn_cls: 2.115  loss_rpn_loc: 0.2883    time: 3.8693  last_time: 4.4125  data_time: 0.0709  last_data_time: 0.0013   lr: 4.9953e-06  \n",
      "\u001b[32m[09/09 01:02:36 d2.utils.events]: \u001b[0m eta: 1:14:36  iter: 39  total_loss: 3.891  loss_cls: 0.7078  loss_box_reg: 0.1829  loss_mask: 0.691  loss_rpn_cls: 1.942  loss_rpn_loc: 0.4196    time: 4.0669  last_time: 4.0970  data_time: 0.0016  last_data_time: 0.0012   lr: 9.9902e-06  \n",
      "\u001b[32m[09/09 01:03:57 d2.utils.events]: \u001b[0m eta: 1:12:52  iter: 59  total_loss: 2.704  loss_cls: 0.6341  loss_box_reg: 0.3535  loss_mask: 0.6862  loss_rpn_cls: 0.7001  loss_rpn_loc: 0.3549    time: 4.0556  last_time: 4.0599  data_time: 0.0013  last_data_time: 0.0017   lr: 1.4985e-05  \n",
      "\u001b[32m[09/09 01:05:19 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 79  total_loss: 2.272  loss_cls: 0.5406  loss_box_reg: 0.2017  loss_mask: 0.6804  loss_rpn_cls: 0.4047  loss_rpn_loc: 0.3569    time: 4.0693  last_time: 3.4116  data_time: 0.0014  last_data_time: 0.0011   lr: 1.998e-05  \n",
      "\u001b[32m[09/09 01:06:37 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 99  total_loss: 2.197  loss_cls: 0.4602  loss_box_reg: 0.2046  loss_mask: 0.6701  loss_rpn_cls: 0.4373  loss_rpn_loc: 0.3341    time: 4.0339  last_time: 3.1069  data_time: 0.0014  last_data_time: 0.0018   lr: 2.4975e-05  \n",
      "\u001b[32m[09/09 01:07:58 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 119  total_loss: 1.881  loss_cls: 0.4119  loss_box_reg: 0.2749  loss_mask: 0.6573  loss_rpn_cls: 0.2956  loss_rpn_loc: 0.3018    time: 4.0388  last_time: 4.3289  data_time: 0.0014  last_data_time: 0.0018   lr: 2.997e-05  \n",
      "\u001b[32m[09/09 01:09:21 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 139  total_loss: 2.319  loss_cls: 0.4142  loss_box_reg: 0.2565  loss_mask: 0.6529  loss_rpn_cls: 0.4559  loss_rpn_loc: 0.4154    time: 4.0533  last_time: 4.0045  data_time: 0.0013  last_data_time: 0.0010   lr: 3.4965e-05  \n",
      "\u001b[32m[09/09 01:10:34 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 159  total_loss: 2.003  loss_cls: 0.3707  loss_box_reg: 0.2071  loss_mask: 0.6446  loss_rpn_cls: 0.3384  loss_rpn_loc: 0.2996    time: 4.0061  last_time: 4.4009  data_time: 0.0012  last_data_time: 0.0010   lr: 3.996e-05  \n",
      "\u001b[32m[09/09 01:11:50 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 179  total_loss: 1.865  loss_cls: 0.3681  loss_box_reg: 0.2511  loss_mask: 0.631  loss_rpn_cls: 0.2852  loss_rpn_loc: 0.2897    time: 3.9829  last_time: 3.5151  data_time: 0.0011  last_data_time: 0.0013   lr: 4.4955e-05  \n",
      "\u001b[32m[09/09 01:13:07 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 199  total_loss: 1.824  loss_cls: 0.3781  loss_box_reg: 0.276  loss_mask: 0.6024  loss_rpn_cls: 0.3375  loss_rpn_loc: 0.2735    time: 3.9701  last_time: 3.8320  data_time: 0.0011  last_data_time: 0.0014   lr: 4.995e-05  \n",
      "\u001b[32m[09/09 01:14:27 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 219  total_loss: 2.018  loss_cls: 0.4194  loss_box_reg: 0.3387  loss_mask: 0.6046  loss_rpn_cls: 0.3814  loss_rpn_loc: 0.2705    time: 3.9700  last_time: 3.7782  data_time: 0.0012  last_data_time: 0.0015   lr: 5.4945e-05  \n",
      "\u001b[32m[09/09 01:15:48 d2.utils.events]: \u001b[0m eta: 0:58:32  iter: 239  total_loss: 2.014  loss_cls: 0.414  loss_box_reg: 0.2791  loss_mask: 0.5791  loss_rpn_cls: 0.3489  loss_rpn_loc: 0.3704    time: 3.9761  last_time: 3.7199  data_time: 0.0013  last_data_time: 0.0015   lr: 5.994e-05  \n",
      "\u001b[32m[09/09 01:17:04 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 259  total_loss: 1.83  loss_cls: 0.3525  loss_box_reg: 0.3813  loss_mask: 0.5667  loss_rpn_cls: 0.2665  loss_rpn_loc: 0.2624    time: 3.9631  last_time: 4.2226  data_time: 0.0011  last_data_time: 0.0011   lr: 6.4935e-05  \n",
      "\u001b[32m[09/09 01:18:21 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 279  total_loss: 2.085  loss_cls: 0.382  loss_box_reg: 0.3185  loss_mask: 0.5668  loss_rpn_cls: 0.2983  loss_rpn_loc: 0.3343    time: 3.9573  last_time: 3.2033  data_time: 0.0014  last_data_time: 0.0018   lr: 6.993e-05  \n",
      "\u001b[32m[09/09 01:19:39 d2.utils.events]: \u001b[0m eta: 0:54:27  iter: 299  total_loss: 1.943  loss_cls: 0.387  loss_box_reg: 0.381  loss_mask: 0.5482  loss_rpn_cls: 0.2564  loss_rpn_loc: 0.2801    time: 3.9521  last_time: 4.0714  data_time: 0.0012  last_data_time: 0.0011   lr: 7.4925e-05  \n",
      "\u001b[32m[09/09 01:20:55 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 319  total_loss: 2.109  loss_cls: 0.4268  loss_box_reg: 0.4082  loss_mask: 0.5437  loss_rpn_cls: 0.2754  loss_rpn_loc: 0.3192    time: 3.9432  last_time: 4.0096  data_time: 0.0011  last_data_time: 0.0017   lr: 7.992e-05  \n",
      "\u001b[32m[09/09 01:22:11 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 339  total_loss: 1.941  loss_cls: 0.3792  loss_box_reg: 0.3649  loss_mask: 0.5265  loss_rpn_cls: 0.2999  loss_rpn_loc: 0.3151    time: 3.9340  last_time: 3.5655  data_time: 0.0012  last_data_time: 0.0011   lr: 8.4915e-05  \n",
      "\u001b[32m[09/09 01:23:27 d2.utils.events]: \u001b[0m eta: 0:50:10  iter: 359  total_loss: 2.03  loss_cls: 0.427  loss_box_reg: 0.3783  loss_mask: 0.5281  loss_rpn_cls: 0.3039  loss_rpn_loc: 0.3353    time: 3.9256  last_time: 4.2425  data_time: 0.0012  last_data_time: 0.0011   lr: 8.991e-05  \n",
      "\u001b[32m[09/09 01:24:42 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 379  total_loss: 2.076  loss_cls: 0.3954  loss_box_reg: 0.366  loss_mask: 0.517  loss_rpn_cls: 0.356  loss_rpn_loc: 0.3079    time: 3.9183  last_time: 4.4050  data_time: 0.0012  last_data_time: 0.0015   lr: 9.4905e-05  \n",
      "\u001b[32m[09/09 01:26:02 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 399  total_loss: 1.838  loss_cls: 0.3792  loss_box_reg: 0.4032  loss_mask: 0.5223  loss_rpn_cls: 0.2916  loss_rpn_loc: 0.3069    time: 3.9222  last_time: 4.0512  data_time: 0.0013  last_data_time: 0.0016   lr: 9.99e-05  \n",
      "\u001b[32m[09/09 01:27:20 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 419  total_loss: 1.77  loss_cls: 0.3506  loss_box_reg: 0.3712  loss_mask: 0.4952  loss_rpn_cls: 0.2833  loss_rpn_loc: 0.2739    time: 3.9195  last_time: 3.4073  data_time: 0.0012  last_data_time: 0.0009   lr: 0.0001049  \n",
      "\u001b[32m[09/09 01:28:40 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 439  total_loss: 1.745  loss_cls: 0.3753  loss_box_reg: 0.3996  loss_mask: 0.4724  loss_rpn_cls: 0.2152  loss_rpn_loc: 0.2447    time: 3.9243  last_time: 3.7111  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00010989  \n",
      "\u001b[32m[09/09 01:30:00 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 459  total_loss: 1.721  loss_cls: 0.3468  loss_box_reg: 0.3207  loss_mask: 0.4559  loss_rpn_cls: 0.3463  loss_rpn_loc: 0.2666    time: 3.9261  last_time: 3.6747  data_time: 0.0012  last_data_time: 0.0018   lr: 0.00011489  \n",
      "\u001b[32m[09/09 01:31:18 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 479  total_loss: 1.883  loss_cls: 0.3877  loss_box_reg: 0.3466  loss_mask: 0.4888  loss_rpn_cls: 0.3347  loss_rpn_loc: 0.3434    time: 3.9268  last_time: 4.4219  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00011988  \n",
      "\u001b[32m[09/09 01:32:39 d2.utils.events]: \u001b[0m eta: 0:40:58  iter: 499  total_loss: 1.897  loss_cls: 0.4097  loss_box_reg: 0.5287  loss_mask: 0.487  loss_rpn_cls: 0.2526  loss_rpn_loc: 0.2749    time: 3.9308  last_time: 4.5561  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00012488  \n",
      "\u001b[32m[09/09 01:33:56 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 519  total_loss: 1.705  loss_cls: 0.3283  loss_box_reg: 0.3634  loss_mask: 0.5078  loss_rpn_cls: 0.2629  loss_rpn_loc: 0.2297    time: 3.9281  last_time: 4.4984  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00012987  \n",
      "\u001b[32m[09/09 01:35:16 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 539  total_loss: 1.754  loss_cls: 0.3701  loss_box_reg: 0.4285  loss_mask: 0.4787  loss_rpn_cls: 0.1961  loss_rpn_loc: 0.2712    time: 3.9311  last_time: 3.3662  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00013487  \n",
      "\u001b[32m[09/09 01:36:36 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 559  total_loss: 1.936  loss_cls: 0.3832  loss_box_reg: 0.4498  loss_mask: 0.473  loss_rpn_cls: 0.2878  loss_rpn_loc: 0.2792    time: 3.9334  last_time: 3.1745  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00013986  \n",
      "\u001b[32m[09/09 01:37:58 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 579  total_loss: 1.924  loss_cls: 0.4198  loss_box_reg: 0.4629  loss_mask: 0.4706  loss_rpn_cls: 0.2744  loss_rpn_loc: 0.2824    time: 3.9393  last_time: 4.5603  data_time: 0.0014  last_data_time: 0.0003   lr: 0.00014486  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 01:39:16 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 599  total_loss: 1.817  loss_cls: 0.3818  loss_box_reg: 0.3158  loss_mask: 0.4499  loss_rpn_cls: 0.2546  loss_rpn_loc: 0.2534    time: 3.9369  last_time: 4.3976  data_time: 0.0012  last_data_time: 0.0008   lr: 0.00014985  \n",
      "\u001b[32m[09/09 01:40:31 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 619  total_loss: 1.744  loss_cls: 0.3448  loss_box_reg: 0.3154  loss_mask: 0.4771  loss_rpn_cls: 0.3075  loss_rpn_loc: 0.2816    time: 3.9321  last_time: 3.3826  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00015485  \n",
      "\u001b[32m[09/09 01:41:48 d2.utils.events]: \u001b[0m eta: 0:31:30  iter: 639  total_loss: 1.85  loss_cls: 0.3631  loss_box_reg: 0.3785  loss_mask: 0.4789  loss_rpn_cls: 0.2928  loss_rpn_loc: 0.3147    time: 3.9296  last_time: 4.1614  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00015984  \n",
      "\u001b[32m[09/09 01:43:06 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 659  total_loss: 1.944  loss_cls: 0.3629  loss_box_reg: 0.4342  loss_mask: 0.475  loss_rpn_cls: 0.3213  loss_rpn_loc: 0.2607    time: 3.9280  last_time: 3.9556  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00016484  \n",
      "\u001b[32m[09/09 01:44:23 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 679  total_loss: 1.727  loss_cls: 0.3428  loss_box_reg: 0.4064  loss_mask: 0.4606  loss_rpn_cls: 0.282  loss_rpn_loc: 0.2888    time: 3.9258  last_time: 4.1373  data_time: 0.0012  last_data_time: 0.0008   lr: 0.00016983  \n",
      "\u001b[32m[09/09 01:45:42 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 699  total_loss: 1.811  loss_cls: 0.393  loss_box_reg: 0.4139  loss_mask: 0.4757  loss_rpn_cls: 0.268  loss_rpn_loc: 0.2944    time: 3.9270  last_time: 2.8148  data_time: 0.0012  last_data_time: 0.0015   lr: 0.00017483  \n",
      "\u001b[32m[09/09 01:47:02 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 719  total_loss: 1.809  loss_cls: 0.3752  loss_box_reg: 0.4034  loss_mask: 0.4872  loss_rpn_cls: 0.2455  loss_rpn_loc: 0.2121    time: 3.9283  last_time: 4.5227  data_time: 0.0012  last_data_time: 0.0015   lr: 0.00017982  \n",
      "\u001b[32m[09/09 01:48:18 d2.utils.events]: \u001b[0m eta: 0:24:45  iter: 739  total_loss: 1.763  loss_cls: 0.349  loss_box_reg: 0.3797  loss_mask: 0.4619  loss_rpn_cls: 0.2076  loss_rpn_loc: 0.2469    time: 3.9250  last_time: 4.3502  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00018482  \n",
      "\u001b[32m[09/09 01:49:37 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 759  total_loss: 1.804  loss_cls: 0.3949  loss_box_reg: 0.4875  loss_mask: 0.4672  loss_rpn_cls: 0.2732  loss_rpn_loc: 0.351    time: 3.9254  last_time: 4.5613  data_time: 0.0013  last_data_time: 0.0019   lr: 0.00018981  \n",
      "\u001b[32m[09/09 01:50:55 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 779  total_loss: 1.918  loss_cls: 0.3708  loss_box_reg: 0.4239  loss_mask: 0.4532  loss_rpn_cls: 0.2103  loss_rpn_loc: 0.279    time: 3.9254  last_time: 3.1185  data_time: 0.0012  last_data_time: 0.0013   lr: 0.00019481  \n",
      "\u001b[32m[09/09 01:52:14 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 799  total_loss: 1.704  loss_cls: 0.3775  loss_box_reg: 0.409  loss_mask: 0.4523  loss_rpn_cls: 0.2331  loss_rpn_loc: 0.2934    time: 3.9259  last_time: 4.7227  data_time: 0.0012  last_data_time: 0.0008   lr: 0.0001998  \n",
      "\u001b[32m[09/09 01:53:32 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 819  total_loss: 1.912  loss_cls: 0.4108  loss_box_reg: 0.4837  loss_mask: 0.4482  loss_rpn_cls: 0.2992  loss_rpn_loc: 0.3091    time: 3.9250  last_time: 3.1691  data_time: 0.0014  last_data_time: 0.0017   lr: 0.0002048  \n",
      "\u001b[32m[09/09 01:54:55 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 839  total_loss: 1.786  loss_cls: 0.3477  loss_box_reg: 0.4332  loss_mask: 0.4602  loss_rpn_cls: 0.2373  loss_rpn_loc: 0.2709    time: 3.9302  last_time: 4.3702  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00020979  \n",
      "\u001b[32m[09/09 01:56:16 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 859  total_loss: 1.812  loss_cls: 0.3886  loss_box_reg: 0.3584  loss_mask: 0.4869  loss_rpn_cls: 0.2624  loss_rpn_loc: 0.3383    time: 3.9333  last_time: 4.3831  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00021479  \n",
      "\u001b[32m[09/09 01:57:37 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 879  total_loss: 1.812  loss_cls: 0.3747  loss_box_reg: 0.4097  loss_mask: 0.4895  loss_rpn_cls: 0.2771  loss_rpn_loc: 0.2825    time: 3.9359  last_time: 3.9635  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00021978  \n",
      "\u001b[32m[09/09 01:58:59 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 899  total_loss: 1.743  loss_cls: 0.3527  loss_box_reg: 0.4639  loss_mask: 0.4494  loss_rpn_cls: 0.2438  loss_rpn_loc: 0.2501    time: 3.9390  last_time: 4.6454  data_time: 0.0013  last_data_time: 0.0024   lr: 0.00022478  \n",
      "\u001b[32m[09/09 02:00:20 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 919  total_loss: 1.767  loss_cls: 0.3988  loss_box_reg: 0.5245  loss_mask: 0.4647  loss_rpn_cls: 0.259  loss_rpn_loc: 0.2557    time: 3.9418  last_time: 4.2863  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00022977  \n",
      "\u001b[32m[09/09 02:01:41 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 939  total_loss: 1.737  loss_cls: 0.3839  loss_box_reg: 0.459  loss_mask: 0.4818  loss_rpn_cls: 0.2146  loss_rpn_loc: 0.1858    time: 3.9444  last_time: 4.4135  data_time: 0.0012  last_data_time: 0.0010   lr: 0.00023477  \n",
      "\u001b[32m[09/09 02:02:57 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 959  total_loss: 1.898  loss_cls: 0.4212  loss_box_reg: 0.5485  loss_mask: 0.4549  loss_rpn_cls: 0.238  loss_rpn_loc: 0.2807    time: 3.9405  last_time: 4.6369  data_time: 0.0012  last_data_time: 0.0009   lr: 0.00023976  \n",
      "\u001b[32m[09/09 02:04:18 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 979  total_loss: 1.675  loss_cls: 0.3583  loss_box_reg: 0.4289  loss_mask: 0.4604  loss_rpn_cls: 0.2093  loss_rpn_loc: 0.2009    time: 3.9433  last_time: 4.6662  data_time: 0.0012  last_data_time: 0.0008   lr: 0.00024476  \n",
      "\u001b[32m[09/09 02:05:36 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 999  total_loss: 1.887  loss_cls: 0.3536  loss_box_reg: 0.3779  loss_mask: 0.4635  loss_rpn_cls: 0.2122  loss_rpn_loc: 0.3562    time: 3.9419  last_time: 3.4708  data_time: 0.0012  last_data_time: 0.0015   lr: 0.00024975  \n",
      "\u001b[32m[09/09 02:06:54 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1019  total_loss: 1.67  loss_cls: 0.3291  loss_box_reg: 0.3589  loss_mask: 0.4668  loss_rpn_cls: 0.2014  loss_rpn_loc: 0.2551    time: 3.9412  last_time: 3.9717  data_time: 0.0012  last_data_time: 0.0018   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:08:12 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 1039  total_loss: 1.982  loss_cls: 0.4382  loss_box_reg: 0.6112  loss_mask: 0.4587  loss_rpn_cls: 0.2411  loss_rpn_loc: 0.2867    time: 3.9404  last_time: 3.5673  data_time: 0.0013  last_data_time: 0.0010   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:09:29 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 1059  total_loss: 1.904  loss_cls: 0.4023  loss_box_reg: 0.5261  loss_mask: 0.4757  loss_rpn_cls: 0.2823  loss_rpn_loc: 0.2718    time: 3.9392  last_time: 4.3550  data_time: 0.0013  last_data_time: 0.0008   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:10:49 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 1079  total_loss: 1.783  loss_cls: 0.3464  loss_box_reg: 0.4179  loss_mask: 0.4512  loss_rpn_cls: 0.1842  loss_rpn_loc: 0.2253    time: 3.9399  last_time: 4.2492  data_time: 0.0012  last_data_time: 0.0016   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:12:07 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 1099  total_loss: 1.757  loss_cls: 0.358  loss_box_reg: 0.4929  loss_mask: 0.4726  loss_rpn_cls: 0.2363  loss_rpn_loc: 0.3014    time: 3.9393  last_time: 4.4533  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:12:48 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1110  total_loss: 1.681  loss_cls: 0.3879  loss_box_reg: 0.4002  loss_mask: 0.4798  loss_rpn_cls: 0.2389  loss_rpn_loc: 0.2444    time: 3.9372  last_time: 3.3471  data_time: 0.0011  last_data_time: 0.0012   lr: 0.00025  \n",
      "\u001b[32m[09/09 02:12:48 d2.engine.hooks]: \u001b[0mOverall training speed: 1109 iterations in 1:12:46 (3.9372 s / it)\n",
      "\u001b[32m[09/09 02:12:48 d2.engine.hooks]: \u001b[0mTotal training time: 1:12:50 (0:00:04 on hooks)\n",
      "\u001b[32m[09/09 02:12:48 d2.data.datasets.coco]: \u001b[0mLoaded 1866 images in COCO format from test_output_coco_annotations.json\n",
      "\u001b[32m[09/09 02:12:48 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   damage   | 9961         |\n",
      "|            |              |\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:12:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 02:12:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/09 02:12:48 d2.data.common]: \u001b[0mSerializing 1866 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 02:12:48 d2.data.common]: \u001b[0mSerialized dataset takes 3.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 02:12:48 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 02:12:48 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 02:12:49 d2.data.datasets.coco]: \u001b[0mLoaded 1866 images in COCO format from test_output_coco_annotations.json\n",
      "\u001b[32m[09/09 02:12:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 02:12:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/09 02:12:49 d2.data.common]: \u001b[0mSerializing 1866 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 02:12:49 d2.data.common]: \u001b[0mSerialized dataset takes 3.36 MiB\n",
      "\u001b[32m[09/09 02:12:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 1866 batches\n",
      "\u001b[32m[09/09 02:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/1866. Dataloading: 0.0002 s/iter. Inference: 0.9299 s/iter. Eval: 0.1069 s/iter. Total: 1.0370 s/iter. ETA=0:32:03\n",
      "\u001b[32m[09/09 02:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 16/1866. Dataloading: 0.0003 s/iter. Inference: 0.9325 s/iter. Eval: 0.1077 s/iter. Total: 1.0406 s/iter. ETA=0:32:05\n",
      "\u001b[32m[09/09 02:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 21/1866. Dataloading: 0.0003 s/iter. Inference: 0.9378 s/iter. Eval: 0.1078 s/iter. Total: 1.0460 s/iter. ETA=0:32:09\n",
      "\u001b[32m[09/09 02:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 26/1866. Dataloading: 0.0003 s/iter. Inference: 0.9408 s/iter. Eval: 0.1075 s/iter. Total: 1.0488 s/iter. ETA=0:32:09\n",
      "\u001b[32m[09/09 02:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 31/1866. Dataloading: 0.0003 s/iter. Inference: 0.9441 s/iter. Eval: 0.1076 s/iter. Total: 1.0523 s/iter. ETA=0:32:10\n",
      "\u001b[32m[09/09 02:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 36/1866. Dataloading: 0.0003 s/iter. Inference: 0.9480 s/iter. Eval: 0.1072 s/iter. Total: 1.0557 s/iter. ETA=0:32:11\n",
      "\u001b[32m[09/09 02:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 41/1866. Dataloading: 0.0003 s/iter. Inference: 0.9446 s/iter. Eval: 0.1068 s/iter. Total: 1.0519 s/iter. ETA=0:31:59\n",
      "\u001b[32m[09/09 02:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 46/1866. Dataloading: 0.0003 s/iter. Inference: 0.9411 s/iter. Eval: 0.1067 s/iter. Total: 1.0484 s/iter. ETA=0:31:48\n",
      "\u001b[32m[09/09 02:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/1866. Dataloading: 0.0003 s/iter. Inference: 0.9420 s/iter. Eval: 0.1066 s/iter. Total: 1.0491 s/iter. ETA=0:31:44\n",
      "\u001b[32m[09/09 02:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 56/1866. Dataloading: 0.0003 s/iter. Inference: 0.9415 s/iter. Eval: 0.1067 s/iter. Total: 1.0487 s/iter. ETA=0:31:38\n",
      "\u001b[32m[09/09 02:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 61/1866. Dataloading: 0.0003 s/iter. Inference: 0.9438 s/iter. Eval: 0.1065 s/iter. Total: 1.0508 s/iter. ETA=0:31:36\n",
      "\u001b[32m[09/09 02:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 66/1866. Dataloading: 0.0003 s/iter. Inference: 0.9438 s/iter. Eval: 0.1065 s/iter. Total: 1.0508 s/iter. ETA=0:31:31\n",
      "\u001b[32m[09/09 02:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 71/1866. Dataloading: 0.0003 s/iter. Inference: 0.9427 s/iter. Eval: 0.1065 s/iter. Total: 1.0497 s/iter. ETA=0:31:24\n",
      "\u001b[32m[09/09 02:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 76/1866. Dataloading: 0.0003 s/iter. Inference: 0.9422 s/iter. Eval: 0.1063 s/iter. Total: 1.0491 s/iter. ETA=0:31:17\n",
      "\u001b[32m[09/09 02:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 81/1866. Dataloading: 0.0003 s/iter. Inference: 0.9423 s/iter. Eval: 0.1063 s/iter. Total: 1.0492 s/iter. ETA=0:31:12\n",
      "\u001b[32m[09/09 02:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 86/1866. Dataloading: 0.0003 s/iter. Inference: 0.9415 s/iter. Eval: 0.1063 s/iter. Total: 1.0482 s/iter. ETA=0:31:05\n",
      "\u001b[32m[09/09 02:14:27 d2.evaluation.evaluator]: \u001b[0mInference done 91/1866. Dataloading: 0.0003 s/iter. Inference: 0.9425 s/iter. Eval: 0.1063 s/iter. Total: 1.0493 s/iter. ETA=0:31:02\n",
      "\u001b[32m[09/09 02:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 96/1866. Dataloading: 0.0003 s/iter. Inference: 0.9418 s/iter. Eval: 0.1063 s/iter. Total: 1.0486 s/iter. ETA=0:30:56\n",
      "\u001b[32m[09/09 02:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 101/1866. Dataloading: 0.0003 s/iter. Inference: 0.9426 s/iter. Eval: 0.1065 s/iter. Total: 1.0496 s/iter. ETA=0:30:52\n",
      "\u001b[32m[09/09 02:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 106/1866. Dataloading: 0.0003 s/iter. Inference: 0.9432 s/iter. Eval: 0.1066 s/iter. Total: 1.0502 s/iter. ETA=0:30:48\n",
      "\u001b[32m[09/09 02:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 111/1866. Dataloading: 0.0003 s/iter. Inference: 0.9441 s/iter. Eval: 0.1067 s/iter. Total: 1.0512 s/iter. ETA=0:30:44\n",
      "\u001b[32m[09/09 02:14:53 d2.evaluation.evaluator]: \u001b[0mInference done 116/1866. Dataloading: 0.0003 s/iter. Inference: 0.9439 s/iter. Eval: 0.1066 s/iter. Total: 1.0510 s/iter. ETA=0:30:39\n",
      "\u001b[32m[09/09 02:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 121/1866. Dataloading: 0.0003 s/iter. Inference: 0.9453 s/iter. Eval: 0.1066 s/iter. Total: 1.0524 s/iter. ETA=0:30:36\n",
      "\u001b[32m[09/09 02:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 126/1866. Dataloading: 0.0003 s/iter. Inference: 0.9452 s/iter. Eval: 0.1066 s/iter. Total: 1.0523 s/iter. ETA=0:30:30\n",
      "\u001b[32m[09/09 02:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 131/1866. Dataloading: 0.0003 s/iter. Inference: 0.9453 s/iter. Eval: 0.1065 s/iter. Total: 1.0523 s/iter. ETA=0:30:25\n",
      "\u001b[32m[09/09 02:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 136/1866. Dataloading: 0.0003 s/iter. Inference: 0.9460 s/iter. Eval: 0.1067 s/iter. Total: 1.0532 s/iter. ETA=0:30:21\n",
      "\u001b[32m[09/09 02:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 141/1866. Dataloading: 0.0003 s/iter. Inference: 0.9488 s/iter. Eval: 0.1068 s/iter. Total: 1.0562 s/iter. ETA=0:30:21\n",
      "\u001b[32m[09/09 02:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 146/1866. Dataloading: 0.0003 s/iter. Inference: 0.9509 s/iter. Eval: 0.1070 s/iter. Total: 1.0584 s/iter. ETA=0:30:20\n",
      "\u001b[32m[09/09 02:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 151/1866. Dataloading: 0.0003 s/iter. Inference: 0.9525 s/iter. Eval: 0.1069 s/iter. Total: 1.0600 s/iter. ETA=0:30:17\n",
      "\u001b[32m[09/09 02:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 156/1866. Dataloading: 0.0003 s/iter. Inference: 0.9530 s/iter. Eval: 0.1069 s/iter. Total: 1.0604 s/iter. ETA=0:30:13\n",
      "\u001b[32m[09/09 02:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 161/1866. Dataloading: 0.0003 s/iter. Inference: 0.9534 s/iter. Eval: 0.1069 s/iter. Total: 1.0608 s/iter. ETA=0:30:08\n",
      "\u001b[32m[09/09 02:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 166/1866. Dataloading: 0.0003 s/iter. Inference: 0.9541 s/iter. Eval: 0.1069 s/iter. Total: 1.0614 s/iter. ETA=0:30:04\n",
      "\u001b[32m[09/09 02:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 171/1866. Dataloading: 0.0003 s/iter. Inference: 0.9543 s/iter. Eval: 0.1069 s/iter. Total: 1.0617 s/iter. ETA=0:29:59\n",
      "\u001b[32m[09/09 02:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 176/1866. Dataloading: 0.0003 s/iter. Inference: 0.9545 s/iter. Eval: 0.1069 s/iter. Total: 1.0619 s/iter. ETA=0:29:54\n",
      "\u001b[32m[09/09 02:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 181/1866. Dataloading: 0.0003 s/iter. Inference: 0.9547 s/iter. Eval: 0.1069 s/iter. Total: 1.0622 s/iter. ETA=0:29:49\n",
      "\u001b[32m[09/09 02:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 186/1866. Dataloading: 0.0003 s/iter. Inference: 0.9550 s/iter. Eval: 0.1069 s/iter. Total: 1.0624 s/iter. ETA=0:29:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 191/1866. Dataloading: 0.0003 s/iter. Inference: 0.9549 s/iter. Eval: 0.1069 s/iter. Total: 1.0623 s/iter. ETA=0:29:39\n",
      "\u001b[32m[09/09 02:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 196/1866. Dataloading: 0.0003 s/iter. Inference: 0.9553 s/iter. Eval: 0.1074 s/iter. Total: 1.0632 s/iter. ETA=0:29:35\n",
      "\u001b[32m[09/09 02:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 201/1866. Dataloading: 0.0003 s/iter. Inference: 0.9553 s/iter. Eval: 0.1074 s/iter. Total: 1.0632 s/iter. ETA=0:29:30\n",
      "\u001b[32m[09/09 02:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 206/1866. Dataloading: 0.0003 s/iter. Inference: 0.9558 s/iter. Eval: 0.1074 s/iter. Total: 1.0637 s/iter. ETA=0:29:25\n",
      "\u001b[32m[09/09 02:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 211/1866. Dataloading: 0.0003 s/iter. Inference: 0.9557 s/iter. Eval: 0.1074 s/iter. Total: 1.0637 s/iter. ETA=0:29:20\n",
      "\u001b[32m[09/09 02:16:41 d2.evaluation.evaluator]: \u001b[0mInference done 216/1866. Dataloading: 0.0003 s/iter. Inference: 0.9574 s/iter. Eval: 0.1075 s/iter. Total: 1.0654 s/iter. ETA=0:29:17\n",
      "\u001b[32m[09/09 02:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 221/1866. Dataloading: 0.0003 s/iter. Inference: 0.9578 s/iter. Eval: 0.1076 s/iter. Total: 1.0659 s/iter. ETA=0:29:13\n",
      "\u001b[32m[09/09 02:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 226/1866. Dataloading: 0.0003 s/iter. Inference: 0.9579 s/iter. Eval: 0.1076 s/iter. Total: 1.0660 s/iter. ETA=0:29:08\n",
      "\u001b[32m[09/09 02:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 231/1866. Dataloading: 0.0003 s/iter. Inference: 0.9576 s/iter. Eval: 0.1076 s/iter. Total: 1.0658 s/iter. ETA=0:29:02\n",
      "\u001b[32m[09/09 02:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 236/1866. Dataloading: 0.0003 s/iter. Inference: 0.9581 s/iter. Eval: 0.1076 s/iter. Total: 1.0662 s/iter. ETA=0:28:57\n",
      "\u001b[32m[09/09 02:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 241/1866. Dataloading: 0.0003 s/iter. Inference: 0.9584 s/iter. Eval: 0.1076 s/iter. Total: 1.0666 s/iter. ETA=0:28:53\n",
      "\u001b[32m[09/09 02:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 246/1866. Dataloading: 0.0003 s/iter. Inference: 0.9585 s/iter. Eval: 0.1076 s/iter. Total: 1.0666 s/iter. ETA=0:28:47\n",
      "\u001b[32m[09/09 02:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 251/1866. Dataloading: 0.0003 s/iter. Inference: 0.9585 s/iter. Eval: 0.1076 s/iter. Total: 1.0666 s/iter. ETA=0:28:42\n",
      "\u001b[32m[09/09 02:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 256/1866. Dataloading: 0.0003 s/iter. Inference: 0.9585 s/iter. Eval: 0.1076 s/iter. Total: 1.0666 s/iter. ETA=0:28:37\n",
      "\u001b[32m[09/09 02:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 261/1866. Dataloading: 0.0003 s/iter. Inference: 0.9586 s/iter. Eval: 0.1076 s/iter. Total: 1.0667 s/iter. ETA=0:28:32\n",
      "\u001b[32m[09/09 02:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 266/1866. Dataloading: 0.0003 s/iter. Inference: 0.9583 s/iter. Eval: 0.1076 s/iter. Total: 1.0664 s/iter. ETA=0:28:26\n",
      "\u001b[32m[09/09 02:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 271/1866. Dataloading: 0.0003 s/iter. Inference: 0.9584 s/iter. Eval: 0.1075 s/iter. Total: 1.0664 s/iter. ETA=0:28:20\n",
      "\u001b[32m[09/09 02:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 276/1866. Dataloading: 0.0003 s/iter. Inference: 0.9582 s/iter. Eval: 0.1075 s/iter. Total: 1.0662 s/iter. ETA=0:28:15\n",
      "\u001b[32m[09/09 02:17:51 d2.evaluation.evaluator]: \u001b[0mInference done 281/1866. Dataloading: 0.0003 s/iter. Inference: 0.9583 s/iter. Eval: 0.1075 s/iter. Total: 1.0663 s/iter. ETA=0:28:10\n",
      "\u001b[32m[09/09 02:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 286/1866. Dataloading: 0.0003 s/iter. Inference: 0.9579 s/iter. Eval: 0.1075 s/iter. Total: 1.0659 s/iter. ETA=0:28:04\n",
      "\u001b[32m[09/09 02:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 291/1866. Dataloading: 0.0003 s/iter. Inference: 0.9582 s/iter. Eval: 0.1075 s/iter. Total: 1.0662 s/iter. ETA=0:27:59\n",
      "\u001b[32m[09/09 02:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 296/1866. Dataloading: 0.0003 s/iter. Inference: 0.9581 s/iter. Eval: 0.1080 s/iter. Total: 1.0666 s/iter. ETA=0:27:54\n",
      "\u001b[32m[09/09 02:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 301/1866. Dataloading: 0.0003 s/iter. Inference: 0.9583 s/iter. Eval: 0.1080 s/iter. Total: 1.0668 s/iter. ETA=0:27:49\n",
      "\u001b[32m[09/09 02:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 306/1866. Dataloading: 0.0003 s/iter. Inference: 0.9583 s/iter. Eval: 0.1080 s/iter. Total: 1.0667 s/iter. ETA=0:27:44\n",
      "\u001b[32m[09/09 02:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 311/1866. Dataloading: 0.0003 s/iter. Inference: 0.9581 s/iter. Eval: 0.1080 s/iter. Total: 1.0666 s/iter. ETA=0:27:38\n",
      "\u001b[32m[09/09 02:18:28 d2.evaluation.evaluator]: \u001b[0mInference done 316/1866. Dataloading: 0.0003 s/iter. Inference: 0.9581 s/iter. Eval: 0.1080 s/iter. Total: 1.0666 s/iter. ETA=0:27:33\n",
      "\u001b[32m[09/09 02:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 321/1866. Dataloading: 0.0003 s/iter. Inference: 0.9582 s/iter. Eval: 0.1080 s/iter. Total: 1.0666 s/iter. ETA=0:27:27\n",
      "\u001b[32m[09/09 02:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 326/1866. Dataloading: 0.0003 s/iter. Inference: 0.9577 s/iter. Eval: 0.1080 s/iter. Total: 1.0662 s/iter. ETA=0:27:22\n",
      "\u001b[32m[09/09 02:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 331/1866. Dataloading: 0.0003 s/iter. Inference: 0.9584 s/iter. Eval: 0.1079 s/iter. Total: 1.0669 s/iter. ETA=0:27:17\n",
      "\u001b[32m[09/09 02:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 336/1866. Dataloading: 0.0003 s/iter. Inference: 0.9586 s/iter. Eval: 0.1079 s/iter. Total: 1.0671 s/iter. ETA=0:27:12\n",
      "\u001b[32m[09/09 02:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 341/1866. Dataloading: 0.0003 s/iter. Inference: 0.9586 s/iter. Eval: 0.1079 s/iter. Total: 1.0670 s/iter. ETA=0:27:07\n",
      "\u001b[32m[09/09 02:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 346/1866. Dataloading: 0.0003 s/iter. Inference: 0.9592 s/iter. Eval: 0.1079 s/iter. Total: 1.0676 s/iter. ETA=0:27:02\n",
      "\u001b[32m[09/09 02:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 351/1866. Dataloading: 0.0003 s/iter. Inference: 0.9596 s/iter. Eval: 0.1079 s/iter. Total: 1.0681 s/iter. ETA=0:26:58\n",
      "\u001b[32m[09/09 02:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 356/1866. Dataloading: 0.0003 s/iter. Inference: 0.9594 s/iter. Eval: 0.1079 s/iter. Total: 1.0678 s/iter. ETA=0:26:52\n",
      "\u001b[32m[09/09 02:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 361/1866. Dataloading: 0.0003 s/iter. Inference: 0.9603 s/iter. Eval: 0.1079 s/iter. Total: 1.0687 s/iter. ETA=0:26:48\n",
      "\u001b[32m[09/09 02:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 366/1866. Dataloading: 0.0003 s/iter. Inference: 0.9617 s/iter. Eval: 0.1080 s/iter. Total: 1.0702 s/iter. ETA=0:26:45\n",
      "\u001b[32m[09/09 02:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 371/1866. Dataloading: 0.0003 s/iter. Inference: 0.9617 s/iter. Eval: 0.1080 s/iter. Total: 1.0701 s/iter. ETA=0:26:39\n",
      "\u001b[32m[09/09 02:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 376/1866. Dataloading: 0.0003 s/iter. Inference: 0.9617 s/iter. Eval: 0.1080 s/iter. Total: 1.0702 s/iter. ETA=0:26:34\n",
      "\u001b[32m[09/09 02:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 381/1866. Dataloading: 0.0003 s/iter. Inference: 0.9615 s/iter. Eval: 0.1080 s/iter. Total: 1.0700 s/iter. ETA=0:26:28\n",
      "\u001b[32m[09/09 02:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 386/1866. Dataloading: 0.0003 s/iter. Inference: 0.9616 s/iter. Eval: 0.1080 s/iter. Total: 1.0702 s/iter. ETA=0:26:23\n",
      "\u001b[32m[09/09 02:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 391/1866. Dataloading: 0.0003 s/iter. Inference: 0.9617 s/iter. Eval: 0.1080 s/iter. Total: 1.0703 s/iter. ETA=0:26:18\n",
      "\u001b[32m[09/09 02:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 396/1866. Dataloading: 0.0003 s/iter. Inference: 0.9618 s/iter. Eval: 0.1080 s/iter. Total: 1.0704 s/iter. ETA=0:26:13\n",
      "\u001b[32m[09/09 02:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 401/1866. Dataloading: 0.0003 s/iter. Inference: 0.9616 s/iter. Eval: 0.1080 s/iter. Total: 1.0701 s/iter. ETA=0:26:07\n",
      "\u001b[32m[09/09 02:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 406/1866. Dataloading: 0.0003 s/iter. Inference: 0.9616 s/iter. Eval: 0.1080 s/iter. Total: 1.0702 s/iter. ETA=0:26:02\n",
      "\u001b[32m[09/09 02:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 411/1866. Dataloading: 0.0003 s/iter. Inference: 0.9618 s/iter. Eval: 0.1080 s/iter. Total: 1.0703 s/iter. ETA=0:25:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 416/1866. Dataloading: 0.0003 s/iter. Inference: 0.9620 s/iter. Eval: 0.1080 s/iter. Total: 1.0705 s/iter. ETA=0:25:52\n",
      "\u001b[32m[09/09 02:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 421/1866. Dataloading: 0.0003 s/iter. Inference: 0.9616 s/iter. Eval: 0.1080 s/iter. Total: 1.0701 s/iter. ETA=0:25:46\n",
      "\u001b[32m[09/09 02:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 426/1866. Dataloading: 0.0003 s/iter. Inference: 0.9618 s/iter. Eval: 0.1080 s/iter. Total: 1.0703 s/iter. ETA=0:25:41\n",
      "\u001b[32m[09/09 02:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 431/1866. Dataloading: 0.0003 s/iter. Inference: 0.9617 s/iter. Eval: 0.1080 s/iter. Total: 1.0701 s/iter. ETA=0:25:35\n",
      "\u001b[32m[09/09 02:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 436/1866. Dataloading: 0.0003 s/iter. Inference: 0.9624 s/iter. Eval: 0.1080 s/iter. Total: 1.0709 s/iter. ETA=0:25:31\n",
      "\u001b[32m[09/09 02:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 441/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1081 s/iter. Total: 1.0714 s/iter. ETA=0:25:26\n",
      "\u001b[32m[09/09 02:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 446/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1081 s/iter. Total: 1.0713 s/iter. ETA=0:25:21\n",
      "\u001b[32m[09/09 02:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 451/1866. Dataloading: 0.0003 s/iter. Inference: 0.9626 s/iter. Eval: 0.1081 s/iter. Total: 1.0712 s/iter. ETA=0:25:15\n",
      "\u001b[32m[09/09 02:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 456/1866. Dataloading: 0.0003 s/iter. Inference: 0.9624 s/iter. Eval: 0.1081 s/iter. Total: 1.0710 s/iter. ETA=0:25:10\n",
      "\u001b[32m[09/09 02:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 461/1866. Dataloading: 0.0003 s/iter. Inference: 0.9623 s/iter. Eval: 0.1081 s/iter. Total: 1.0709 s/iter. ETA=0:25:04\n",
      "\u001b[32m[09/09 02:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 466/1866. Dataloading: 0.0003 s/iter. Inference: 0.9621 s/iter. Eval: 0.1080 s/iter. Total: 1.0706 s/iter. ETA=0:24:58\n",
      "\u001b[32m[09/09 02:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 471/1866. Dataloading: 0.0003 s/iter. Inference: 0.9625 s/iter. Eval: 0.1081 s/iter. Total: 1.0711 s/iter. ETA=0:24:54\n",
      "\u001b[32m[09/09 02:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 476/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1081 s/iter. Total: 1.0713 s/iter. ETA=0:24:49\n",
      "\u001b[32m[09/09 02:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 481/1866. Dataloading: 0.0003 s/iter. Inference: 0.9626 s/iter. Eval: 0.1081 s/iter. Total: 1.0712 s/iter. ETA=0:24:43\n",
      "\u001b[32m[09/09 02:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 486/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1081 s/iter. Total: 1.0713 s/iter. ETA=0:24:38\n",
      "\u001b[32m[09/09 02:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 491/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1081 s/iter. Total: 1.0717 s/iter. ETA=0:24:33\n",
      "\u001b[32m[09/09 02:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 496/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1081 s/iter. Total: 1.0723 s/iter. ETA=0:24:29\n",
      "\u001b[32m[09/09 02:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 501/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1081 s/iter. Total: 1.0724 s/iter. ETA=0:24:23\n",
      "\u001b[32m[09/09 02:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 506/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1081 s/iter. Total: 1.0729 s/iter. ETA=0:24:19\n",
      "\u001b[32m[09/09 02:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 511/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1081 s/iter. Total: 1.0735 s/iter. ETA=0:24:14\n",
      "\u001b[32m[09/09 02:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 516/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1081 s/iter. Total: 1.0738 s/iter. ETA=0:24:09\n",
      "\u001b[32m[09/09 02:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 521/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1081 s/iter. Total: 1.0743 s/iter. ETA=0:24:04\n",
      "\u001b[32m[09/09 02:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 526/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1081 s/iter. Total: 1.0744 s/iter. ETA=0:23:59\n",
      "\u001b[32m[09/09 02:22:22 d2.evaluation.evaluator]: \u001b[0mInference done 531/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1081 s/iter. Total: 1.0743 s/iter. ETA=0:23:54\n",
      "\u001b[32m[09/09 02:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 536/1866. Dataloading: 0.0003 s/iter. Inference: 0.9658 s/iter. Eval: 0.1081 s/iter. Total: 1.0744 s/iter. ETA=0:23:48\n",
      "\u001b[32m[09/09 02:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 541/1866. Dataloading: 0.0003 s/iter. Inference: 0.9656 s/iter. Eval: 0.1081 s/iter. Total: 1.0742 s/iter. ETA=0:23:43\n",
      "\u001b[32m[09/09 02:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 546/1866. Dataloading: 0.0003 s/iter. Inference: 0.9655 s/iter. Eval: 0.1081 s/iter. Total: 1.0741 s/iter. ETA=0:23:37\n",
      "\u001b[32m[09/09 02:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 551/1866. Dataloading: 0.0003 s/iter. Inference: 0.9655 s/iter. Eval: 0.1081 s/iter. Total: 1.0741 s/iter. ETA=0:23:32\n",
      "\u001b[32m[09/09 02:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 556/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:23:26\n",
      "\u001b[32m[09/09 02:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 561/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1080 s/iter. Total: 1.0735 s/iter. ETA=0:23:20\n",
      "\u001b[32m[09/09 02:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 566/1866. Dataloading: 0.0003 s/iter. Inference: 0.9647 s/iter. Eval: 0.1080 s/iter. Total: 1.0732 s/iter. ETA=0:23:15\n",
      "\u001b[32m[09/09 02:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 571/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1080 s/iter. Total: 1.0731 s/iter. ETA=0:23:09\n",
      "\u001b[32m[09/09 02:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 576/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1080 s/iter. Total: 1.0729 s/iter. ETA=0:23:03\n",
      "\u001b[32m[09/09 02:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 581/1866. Dataloading: 0.0003 s/iter. Inference: 0.9642 s/iter. Eval: 0.1080 s/iter. Total: 1.0728 s/iter. ETA=0:22:58\n",
      "\u001b[32m[09/09 02:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 586/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1080 s/iter. Total: 1.0729 s/iter. ETA=0:22:53\n",
      "\u001b[32m[09/09 02:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 591/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1080 s/iter. Total: 1.0728 s/iter. ETA=0:22:47\n",
      "\u001b[32m[09/09 02:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 596/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1080 s/iter. Total: 1.0726 s/iter. ETA=0:22:42\n",
      "\u001b[32m[09/09 02:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 601/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1080 s/iter. Total: 1.0724 s/iter. ETA=0:22:36\n",
      "\u001b[32m[09/09 02:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 606/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1080 s/iter. Total: 1.0724 s/iter. ETA=0:22:31\n",
      "\u001b[32m[09/09 02:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 611/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1080 s/iter. Total: 1.0724 s/iter. ETA=0:22:25\n",
      "\u001b[32m[09/09 02:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 616/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1080 s/iter. Total: 1.0725 s/iter. ETA=0:22:20\n",
      "\u001b[32m[09/09 02:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 621/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1080 s/iter. Total: 1.0726 s/iter. ETA=0:22:15\n",
      "\u001b[32m[09/09 02:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 626/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1080 s/iter. Total: 1.0726 s/iter. ETA=0:22:09\n",
      "\u001b[32m[09/09 02:24:08 d2.evaluation.evaluator]: \u001b[0mInference done 631/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1080 s/iter. Total: 1.0726 s/iter. ETA=0:22:04\n",
      "\u001b[32m[09/09 02:24:13 d2.evaluation.evaluator]: \u001b[0mInference done 636/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1080 s/iter. Total: 1.0724 s/iter. ETA=0:21:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 641/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1080 s/iter. Total: 1.0723 s/iter. ETA=0:21:53\n",
      "\u001b[32m[09/09 02:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 646/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1080 s/iter. Total: 1.0721 s/iter. ETA=0:21:47\n",
      "\u001b[32m[09/09 02:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 651/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1080 s/iter. Total: 1.0721 s/iter. ETA=0:21:42\n",
      "\u001b[32m[09/09 02:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 656/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1080 s/iter. Total: 1.0721 s/iter. ETA=0:21:37\n",
      "\u001b[32m[09/09 02:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 661/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1080 s/iter. Total: 1.0720 s/iter. ETA=0:21:31\n",
      "\u001b[32m[09/09 02:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 666/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1080 s/iter. Total: 1.0718 s/iter. ETA=0:21:26\n",
      "\u001b[32m[09/09 02:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 671/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0717 s/iter. ETA=0:21:20\n",
      "\u001b[32m[09/09 02:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 676/1866. Dataloading: 0.0003 s/iter. Inference: 0.9630 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:21:15\n",
      "\u001b[32m[09/09 02:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 681/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0716 s/iter. ETA=0:21:09\n",
      "\u001b[32m[09/09 02:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 686/1866. Dataloading: 0.0003 s/iter. Inference: 0.9630 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:21:04\n",
      "\u001b[32m[09/09 02:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 691/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0716 s/iter. ETA=0:20:59\n",
      "\u001b[32m[09/09 02:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 696/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1080 s/iter. Total: 1.0718 s/iter. ETA=0:20:53\n",
      "\u001b[32m[09/09 02:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 701/1866. Dataloading: 0.0003 s/iter. Inference: 0.9630 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:20:48\n",
      "\u001b[32m[09/09 02:25:28 d2.evaluation.evaluator]: \u001b[0mInference done 706/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0713 s/iter. ETA=0:20:42\n",
      "\u001b[32m[09/09 02:25:33 d2.evaluation.evaluator]: \u001b[0mInference done 711/1866. Dataloading: 0.0003 s/iter. Inference: 0.9629 s/iter. Eval: 0.1079 s/iter. Total: 1.0713 s/iter. ETA=0:20:37\n",
      "\u001b[32m[09/09 02:25:38 d2.evaluation.evaluator]: \u001b[0mInference done 716/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:20:31\n",
      "\u001b[32m[09/09 02:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 721/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:20:26\n",
      "\u001b[32m[09/09 02:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 726/1866. Dataloading: 0.0003 s/iter. Inference: 0.9630 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:20:21\n",
      "\u001b[32m[09/09 02:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 731/1866. Dataloading: 0.0003 s/iter. Inference: 0.9629 s/iter. Eval: 0.1080 s/iter. Total: 1.0714 s/iter. ETA=0:20:15\n",
      "\u001b[32m[09/09 02:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 736/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1079 s/iter. Total: 1.0713 s/iter. ETA=0:20:10\n",
      "\u001b[32m[09/09 02:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 741/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:20:05\n",
      "\u001b[32m[09/09 02:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 746/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:19:59\n",
      "\u001b[32m[09/09 02:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 751/1866. Dataloading: 0.0003 s/iter. Inference: 0.9626 s/iter. Eval: 0.1080 s/iter. Total: 1.0711 s/iter. ETA=0:19:54\n",
      "\u001b[32m[09/09 02:26:21 d2.evaluation.evaluator]: \u001b[0mInference done 756/1866. Dataloading: 0.0003 s/iter. Inference: 0.9625 s/iter. Eval: 0.1080 s/iter. Total: 1.0710 s/iter. ETA=0:19:48\n",
      "\u001b[32m[09/09 02:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 761/1866. Dataloading: 0.0003 s/iter. Inference: 0.9626 s/iter. Eval: 0.1079 s/iter. Total: 1.0710 s/iter. ETA=0:19:43\n",
      "\u001b[32m[09/09 02:26:32 d2.evaluation.evaluator]: \u001b[0mInference done 766/1866. Dataloading: 0.0003 s/iter. Inference: 0.9625 s/iter. Eval: 0.1079 s/iter. Total: 1.0709 s/iter. ETA=0:19:38\n",
      "\u001b[32m[09/09 02:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 771/1866. Dataloading: 0.0003 s/iter. Inference: 0.9624 s/iter. Eval: 0.1080 s/iter. Total: 1.0708 s/iter. ETA=0:19:32\n",
      "\u001b[32m[09/09 02:26:42 d2.evaluation.evaluator]: \u001b[0mInference done 776/1866. Dataloading: 0.0003 s/iter. Inference: 0.9625 s/iter. Eval: 0.1080 s/iter. Total: 1.0709 s/iter. ETA=0:19:27\n",
      "\u001b[32m[09/09 02:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 781/1866. Dataloading: 0.0003 s/iter. Inference: 0.9625 s/iter. Eval: 0.1080 s/iter. Total: 1.0710 s/iter. ETA=0:19:22\n",
      "\u001b[32m[09/09 02:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 786/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:19:16\n",
      "\u001b[32m[09/09 02:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 791/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:19:11\n",
      "\u001b[32m[09/09 02:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 796/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1079 s/iter. Total: 1.0712 s/iter. ETA=0:19:06\n",
      "\u001b[32m[09/09 02:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 801/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1079 s/iter. Total: 1.0712 s/iter. ETA=0:19:00\n",
      "\u001b[32m[09/09 02:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 806/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1079 s/iter. Total: 1.0713 s/iter. ETA=0:18:55\n",
      "\u001b[32m[09/09 02:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 811/1866. Dataloading: 0.0003 s/iter. Inference: 0.9629 s/iter. Eval: 0.1079 s/iter. Total: 1.0714 s/iter. ETA=0:18:50\n",
      "\u001b[32m[09/09 02:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 816/1866. Dataloading: 0.0003 s/iter. Inference: 0.9632 s/iter. Eval: 0.1079 s/iter. Total: 1.0716 s/iter. ETA=0:18:45\n",
      "\u001b[32m[09/09 02:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 821/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1079 s/iter. Total: 1.0719 s/iter. ETA=0:18:40\n",
      "\u001b[32m[09/09 02:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 826/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1079 s/iter. Total: 1.0720 s/iter. ETA=0:18:34\n",
      "\u001b[32m[09/09 02:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 831/1866. Dataloading: 0.0003 s/iter. Inference: 0.9634 s/iter. Eval: 0.1079 s/iter. Total: 1.0719 s/iter. ETA=0:18:29\n",
      "\u001b[32m[09/09 02:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 836/1866. Dataloading: 0.0003 s/iter. Inference: 0.9634 s/iter. Eval: 0.1079 s/iter. Total: 1.0719 s/iter. ETA=0:18:24\n",
      "\u001b[32m[09/09 02:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 841/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1079 s/iter. Total: 1.0719 s/iter. ETA=0:18:18\n",
      "\u001b[32m[09/09 02:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 846/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1079 s/iter. Total: 1.0721 s/iter. ETA=0:18:13\n",
      "\u001b[32m[09/09 02:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 851/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1079 s/iter. Total: 1.0721 s/iter. ETA=0:18:08\n",
      "\u001b[32m[09/09 02:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 856/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1079 s/iter. Total: 1.0721 s/iter. ETA=0:18:02\n",
      "\u001b[32m[09/09 02:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 861/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0724 s/iter. ETA=0:17:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:28:20 d2.evaluation.evaluator]: \u001b[0mInference done 866/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:52\n",
      "\u001b[32m[09/09 02:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 871/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:46\n",
      "\u001b[32m[09/09 02:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 876/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:41\n",
      "\u001b[32m[09/09 02:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 881/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:36\n",
      "\u001b[32m[09/09 02:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 886/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1079 s/iter. Total: 1.0722 s/iter. ETA=0:17:30\n",
      "\u001b[32m[09/09 02:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 891/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:25\n",
      "\u001b[32m[09/09 02:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 896/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:20\n",
      "\u001b[32m[09/09 02:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 901/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1079 s/iter. Total: 1.0722 s/iter. ETA=0:17:14\n",
      "\u001b[32m[09/09 02:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 906/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1079 s/iter. Total: 1.0724 s/iter. ETA=0:17:09\n",
      "\u001b[32m[09/09 02:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 911/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0723 s/iter. ETA=0:17:04\n",
      "\u001b[32m[09/09 02:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 916/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0724 s/iter. ETA=0:16:58\n",
      "\u001b[32m[09/09 02:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 921/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1079 s/iter. Total: 1.0724 s/iter. ETA=0:16:53\n",
      "\u001b[32m[09/09 02:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 926/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1079 s/iter. Total: 1.0724 s/iter. ETA=0:16:48\n",
      "\u001b[32m[09/09 02:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 931/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1079 s/iter. Total: 1.0725 s/iter. ETA=0:16:42\n",
      "\u001b[32m[09/09 02:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 936/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1079 s/iter. Total: 1.0725 s/iter. ETA=0:16:37\n",
      "\u001b[32m[09/09 02:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 941/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1079 s/iter. Total: 1.0726 s/iter. ETA=0:16:32\n",
      "\u001b[32m[09/09 02:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 946/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1079 s/iter. Total: 1.0725 s/iter. ETA=0:16:26\n",
      "\u001b[32m[09/09 02:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 951/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1079 s/iter. Total: 1.0725 s/iter. ETA=0:16:21\n",
      "\u001b[32m[09/09 02:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 956/1866. Dataloading: 0.0003 s/iter. Inference: 0.9642 s/iter. Eval: 0.1079 s/iter. Total: 1.0726 s/iter. ETA=0:16:16\n",
      "\u001b[32m[09/09 02:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 961/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1079 s/iter. Total: 1.0731 s/iter. ETA=0:16:11\n",
      "\u001b[32m[09/09 02:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 966/1866. Dataloading: 0.0003 s/iter. Inference: 0.9648 s/iter. Eval: 0.1080 s/iter. Total: 1.0733 s/iter. ETA=0:16:06\n",
      "\u001b[32m[09/09 02:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 971/1866. Dataloading: 0.0003 s/iter. Inference: 0.9648 s/iter. Eval: 0.1080 s/iter. Total: 1.0733 s/iter. ETA=0:16:00\n",
      "\u001b[32m[09/09 02:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 976/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1080 s/iter. Total: 1.0735 s/iter. ETA=0:15:55\n",
      "\u001b[32m[09/09 02:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 981/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1080 s/iter. Total: 1.0735 s/iter. ETA=0:15:50\n",
      "\u001b[32m[09/09 02:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 986/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1079 s/iter. Total: 1.0735 s/iter. ETA=0:15:44\n",
      "\u001b[32m[09/09 02:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 991/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1079 s/iter. Total: 1.0736 s/iter. ETA=0:15:39\n",
      "\u001b[32m[09/09 02:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 996/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1079 s/iter. Total: 1.0735 s/iter. ETA=0:15:33\n",
      "\u001b[32m[09/09 02:30:46 d2.evaluation.evaluator]: \u001b[0mInference done 1001/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1079 s/iter. Total: 1.0737 s/iter. ETA=0:15:28\n",
      "\u001b[32m[09/09 02:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 1006/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1079 s/iter. Total: 1.0735 s/iter. ETA=0:15:23\n",
      "\u001b[32m[09/09 02:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 1011/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1079 s/iter. Total: 1.0734 s/iter. ETA=0:15:17\n",
      "\u001b[32m[09/09 02:31:02 d2.evaluation.evaluator]: \u001b[0mInference done 1016/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1079 s/iter. Total: 1.0733 s/iter. ETA=0:15:12\n",
      "\u001b[32m[09/09 02:31:07 d2.evaluation.evaluator]: \u001b[0mInference done 1021/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1079 s/iter. Total: 1.0733 s/iter. ETA=0:15:06\n",
      "\u001b[32m[09/09 02:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 1026/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1079 s/iter. Total: 1.0734 s/iter. ETA=0:15:01\n",
      "\u001b[32m[09/09 02:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 1031/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1079 s/iter. Total: 1.0737 s/iter. ETA=0:14:56\n",
      "\u001b[32m[09/09 02:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 1036/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1079 s/iter. Total: 1.0736 s/iter. ETA=0:14:51\n",
      "\u001b[32m[09/09 02:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 1041/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:14:45\n",
      "\u001b[32m[09/09 02:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 1046/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:14:40\n",
      "\u001b[32m[09/09 02:31:40 d2.evaluation.evaluator]: \u001b[0mInference done 1051/1866. Dataloading: 0.0003 s/iter. Inference: 0.9654 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:35\n",
      "\u001b[32m[09/09 02:31:45 d2.evaluation.evaluator]: \u001b[0mInference done 1056/1866. Dataloading: 0.0003 s/iter. Inference: 0.9655 s/iter. Eval: 0.1080 s/iter. Total: 1.0740 s/iter. ETA=0:14:29\n",
      "\u001b[32m[09/09 02:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 1061/1866. Dataloading: 0.0003 s/iter. Inference: 0.9654 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:24\n",
      "\u001b[32m[09/09 02:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 1066/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:19\n",
      "\u001b[32m[09/09 02:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 1071/1866. Dataloading: 0.0003 s/iter. Inference: 0.9654 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:13\n",
      "\u001b[32m[09/09 02:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 1076/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:08\n",
      "\u001b[32m[09/09 02:32:12 d2.evaluation.evaluator]: \u001b[0mInference done 1081/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:14:02\n",
      "\u001b[32m[09/09 02:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 1086/1866. Dataloading: 0.0003 s/iter. Inference: 0.9654 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:13:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 1091/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:52\n",
      "\u001b[32m[09/09 02:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 1096/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:46\n",
      "\u001b[32m[09/09 02:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 1101/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:41\n",
      "\u001b[32m[09/09 02:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 1106/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:13:36\n",
      "\u001b[32m[09/09 02:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 1111/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:13:30\n",
      "\u001b[32m[09/09 02:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 1116/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:13:25\n",
      "\u001b[32m[09/09 02:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 1121/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:19\n",
      "\u001b[32m[09/09 02:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 1126/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:14\n",
      "\u001b[32m[09/09 02:33:06 d2.evaluation.evaluator]: \u001b[0mInference done 1131/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0738 s/iter. ETA=0:13:09\n",
      "\u001b[32m[09/09 02:33:11 d2.evaluation.evaluator]: \u001b[0mInference done 1136/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1080 s/iter. Total: 1.0737 s/iter. ETA=0:13:03\n",
      "\u001b[32m[09/09 02:33:16 d2.evaluation.evaluator]: \u001b[0mInference done 1141/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:12:58\n",
      "\u001b[32m[09/09 02:33:22 d2.evaluation.evaluator]: \u001b[0mInference done 1146/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1080 s/iter. Total: 1.0739 s/iter. ETA=0:12:53\n",
      "\u001b[32m[09/09 02:33:27 d2.evaluation.evaluator]: \u001b[0mInference done 1151/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1080 s/iter. Total: 1.0742 s/iter. ETA=0:12:48\n",
      "\u001b[32m[09/09 02:33:33 d2.evaluation.evaluator]: \u001b[0mInference done 1156/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:12:43\n",
      "\u001b[32m[09/09 02:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 1161/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:12:37\n",
      "\u001b[32m[09/09 02:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 1166/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:12:32\n",
      "\u001b[32m[09/09 02:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 1171/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:12:26\n",
      "\u001b[32m[09/09 02:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 1176/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:12:21\n",
      "\u001b[32m[09/09 02:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 1181/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:12:16\n",
      "\u001b[32m[09/09 02:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 1186/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:12:10\n",
      "\u001b[32m[09/09 02:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 1191/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:12:05\n",
      "\u001b[32m[09/09 02:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 1196/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:12:00\n",
      "\u001b[32m[09/09 02:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 1201/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:11:54\n",
      "\u001b[32m[09/09 02:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 1206/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1081 s/iter. Total: 1.0748 s/iter. ETA=0:11:49\n",
      "\u001b[32m[09/09 02:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 1211/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:11:43\n",
      "\u001b[32m[09/09 02:34:38 d2.evaluation.evaluator]: \u001b[0mInference done 1216/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1081 s/iter. Total: 1.0747 s/iter. ETA=0:11:38\n",
      "\u001b[32m[09/09 02:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 1221/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1080 s/iter. Total: 1.0747 s/iter. ETA=0:11:33\n",
      "\u001b[32m[09/09 02:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 1226/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1080 s/iter. Total: 1.0746 s/iter. ETA=0:11:27\n",
      "\u001b[32m[09/09 02:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 1231/1866. Dataloading: 0.0003 s/iter. Inference: 0.9660 s/iter. Eval: 0.1080 s/iter. Total: 1.0746 s/iter. ETA=0:11:22\n",
      "\u001b[32m[09/09 02:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 1236/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1080 s/iter. Total: 1.0746 s/iter. ETA=0:11:17\n",
      "\u001b[32m[09/09 02:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 1241/1866. Dataloading: 0.0003 s/iter. Inference: 0.9660 s/iter. Eval: 0.1082 s/iter. Total: 1.0747 s/iter. ETA=0:11:11\n",
      "\u001b[32m[09/09 02:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 1246/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:11:06\n",
      "\u001b[32m[09/09 02:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 1251/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:11:01\n",
      "\u001b[32m[09/09 02:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 1256/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0750 s/iter. ETA=0:10:55\n",
      "\u001b[32m[09/09 02:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 1261/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:10:50\n",
      "\u001b[32m[09/09 02:35:32 d2.evaluation.evaluator]: \u001b[0mInference done 1266/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:44\n",
      "\u001b[32m[09/09 02:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 1271/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:39\n",
      "\u001b[32m[09/09 02:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 1276/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:10:34\n",
      "\u001b[32m[09/09 02:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 1281/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:10:28\n",
      "\u001b[32m[09/09 02:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 1286/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:23\n",
      "\u001b[32m[09/09 02:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 1291/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:18\n",
      "\u001b[32m[09/09 02:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 1296/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:12\n",
      "\u001b[32m[09/09 02:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 1301/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:07\n",
      "\u001b[32m[09/09 02:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 1306/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:10:01\n",
      "\u001b[32m[09/09 02:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 1311/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:09:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 1316/1866. Dataloading: 0.0003 s/iter. Inference: 0.9662 s/iter. Eval: 0.1082 s/iter. Total: 1.0750 s/iter. ETA=0:09:51\n",
      "\u001b[32m[09/09 02:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 1321/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0750 s/iter. ETA=0:09:45\n",
      "\u001b[32m[09/09 02:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 1326/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0750 s/iter. ETA=0:09:40\n",
      "\u001b[32m[09/09 02:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 1331/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:09:35\n",
      "\u001b[32m[09/09 02:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 1336/1866. Dataloading: 0.0003 s/iter. Inference: 0.9665 s/iter. Eval: 0.1082 s/iter. Total: 1.0752 s/iter. ETA=0:09:29\n",
      "\u001b[32m[09/09 02:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 1341/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:09:24\n",
      "\u001b[32m[09/09 02:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 1346/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0752 s/iter. ETA=0:09:19\n",
      "\u001b[32m[09/09 02:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 1351/1866. Dataloading: 0.0003 s/iter. Inference: 0.9665 s/iter. Eval: 0.1082 s/iter. Total: 1.0752 s/iter. ETA=0:09:13\n",
      "\u001b[32m[09/09 02:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 1356/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:09:08\n",
      "\u001b[32m[09/09 02:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 1361/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:09:02\n",
      "\u001b[32m[09/09 02:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 1366/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:08:57\n",
      "\u001b[32m[09/09 02:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 1371/1866. Dataloading: 0.0003 s/iter. Inference: 0.9664 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:08:52\n",
      "\u001b[32m[09/09 02:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 1376/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0751 s/iter. ETA=0:08:46\n",
      "\u001b[32m[09/09 02:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 1381/1866. Dataloading: 0.0003 s/iter. Inference: 0.9663 s/iter. Eval: 0.1082 s/iter. Total: 1.0750 s/iter. ETA=0:08:41\n",
      "\u001b[32m[09/09 02:37:41 d2.evaluation.evaluator]: \u001b[0mInference done 1386/1866. Dataloading: 0.0003 s/iter. Inference: 0.9661 s/iter. Eval: 0.1082 s/iter. Total: 1.0749 s/iter. ETA=0:08:35\n",
      "\u001b[32m[09/09 02:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 1391/1866. Dataloading: 0.0003 s/iter. Inference: 0.9660 s/iter. Eval: 0.1082 s/iter. Total: 1.0748 s/iter. ETA=0:08:30\n",
      "\u001b[32m[09/09 02:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 1396/1866. Dataloading: 0.0003 s/iter. Inference: 0.9659 s/iter. Eval: 0.1082 s/iter. Total: 1.0747 s/iter. ETA=0:08:25\n",
      "\u001b[32m[09/09 02:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 1401/1866. Dataloading: 0.0003 s/iter. Inference: 0.9659 s/iter. Eval: 0.1082 s/iter. Total: 1.0746 s/iter. ETA=0:08:19\n",
      "\u001b[32m[09/09 02:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 1406/1866. Dataloading: 0.0003 s/iter. Inference: 0.9659 s/iter. Eval: 0.1082 s/iter. Total: 1.0746 s/iter. ETA=0:08:14\n",
      "\u001b[32m[09/09 02:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 1411/1866. Dataloading: 0.0003 s/iter. Inference: 0.9658 s/iter. Eval: 0.1082 s/iter. Total: 1.0745 s/iter. ETA=0:08:08\n",
      "\u001b[32m[09/09 02:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 1416/1866. Dataloading: 0.0003 s/iter. Inference: 0.9658 s/iter. Eval: 0.1082 s/iter. Total: 1.0745 s/iter. ETA=0:08:03\n",
      "\u001b[32m[09/09 02:38:18 d2.evaluation.evaluator]: \u001b[0mInference done 1421/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1082 s/iter. Total: 1.0744 s/iter. ETA=0:07:58\n",
      "\u001b[32m[09/09 02:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 1426/1866. Dataloading: 0.0003 s/iter. Inference: 0.9656 s/iter. Eval: 0.1082 s/iter. Total: 1.0744 s/iter. ETA=0:07:52\n",
      "\u001b[32m[09/09 02:38:28 d2.evaluation.evaluator]: \u001b[0mInference done 1431/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1082 s/iter. Total: 1.0744 s/iter. ETA=0:07:47\n",
      "\u001b[32m[09/09 02:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 1436/1866. Dataloading: 0.0003 s/iter. Inference: 0.9657 s/iter. Eval: 0.1082 s/iter. Total: 1.0744 s/iter. ETA=0:07:41\n",
      "\u001b[32m[09/09 02:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 1441/1866. Dataloading: 0.0003 s/iter. Inference: 0.9656 s/iter. Eval: 0.1082 s/iter. Total: 1.0743 s/iter. ETA=0:07:36\n",
      "\u001b[32m[09/09 02:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 1446/1866. Dataloading: 0.0003 s/iter. Inference: 0.9655 s/iter. Eval: 0.1082 s/iter. Total: 1.0742 s/iter. ETA=0:07:31\n",
      "\u001b[32m[09/09 02:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 1451/1866. Dataloading: 0.0003 s/iter. Inference: 0.9654 s/iter. Eval: 0.1082 s/iter. Total: 1.0742 s/iter. ETA=0:07:25\n",
      "\u001b[32m[09/09 02:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 1456/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1082 s/iter. Total: 1.0740 s/iter. ETA=0:07:20\n",
      "\u001b[32m[09/09 02:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 1461/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1082 s/iter. Total: 1.0740 s/iter. ETA=0:07:14\n",
      "\u001b[32m[09/09 02:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 1466/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1082 s/iter. Total: 1.0739 s/iter. ETA=0:07:09\n",
      "\u001b[32m[09/09 02:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 1471/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:07:04\n",
      "\u001b[32m[09/09 02:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 1476/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1082 s/iter. Total: 1.0740 s/iter. ETA=0:06:58\n",
      "\u001b[32m[09/09 02:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 1481/1866. Dataloading: 0.0003 s/iter. Inference: 0.9653 s/iter. Eval: 0.1082 s/iter. Total: 1.0740 s/iter. ETA=0:06:53\n",
      "\u001b[32m[09/09 02:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 1486/1866. Dataloading: 0.0003 s/iter. Inference: 0.9652 s/iter. Eval: 0.1082 s/iter. Total: 1.0739 s/iter. ETA=0:06:48\n",
      "\u001b[32m[09/09 02:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 1491/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1082 s/iter. Total: 1.0739 s/iter. ETA=0:06:42\n",
      "\u001b[32m[09/09 02:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 1496/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:37\n",
      "\u001b[32m[09/09 02:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 1501/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:31\n",
      "\u001b[32m[09/09 02:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 1506/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0737 s/iter. ETA=0:06:26\n",
      "\u001b[32m[09/09 02:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 1511/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:21\n",
      "\u001b[32m[09/09 02:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 1516/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:15\n",
      "\u001b[32m[09/09 02:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 1521/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:10\n",
      "\u001b[32m[09/09 02:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 1526/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:06:05\n",
      "\u001b[32m[09/09 02:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 1531/1866. Dataloading: 0.0003 s/iter. Inference: 0.9651 s/iter. Eval: 0.1082 s/iter. Total: 1.0738 s/iter. ETA=0:05:59\n",
      "\u001b[32m[09/09 02:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 1536/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0737 s/iter. ETA=0:05:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 1541/1866. Dataloading: 0.0003 s/iter. Inference: 0.9650 s/iter. Eval: 0.1082 s/iter. Total: 1.0737 s/iter. ETA=0:05:48\n",
      "\u001b[32m[09/09 02:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 1546/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1082 s/iter. Total: 1.0737 s/iter. ETA=0:05:43\n",
      "\u001b[32m[09/09 02:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 1551/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1082 s/iter. Total: 1.0736 s/iter. ETA=0:05:38\n",
      "\u001b[32m[09/09 02:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 1556/1866. Dataloading: 0.0003 s/iter. Inference: 0.9649 s/iter. Eval: 0.1082 s/iter. Total: 1.0736 s/iter. ETA=0:05:32\n",
      "\u001b[32m[09/09 02:40:47 d2.evaluation.evaluator]: \u001b[0mInference done 1561/1866. Dataloading: 0.0003 s/iter. Inference: 0.9648 s/iter. Eval: 0.1082 s/iter. Total: 1.0735 s/iter. ETA=0:05:27\n",
      "\u001b[32m[09/09 02:40:52 d2.evaluation.evaluator]: \u001b[0mInference done 1566/1866. Dataloading: 0.0003 s/iter. Inference: 0.9647 s/iter. Eval: 0.1082 s/iter. Total: 1.0734 s/iter. ETA=0:05:22\n",
      "\u001b[32m[09/09 02:40:57 d2.evaluation.evaluator]: \u001b[0mInference done 1571/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0734 s/iter. ETA=0:05:16\n",
      "\u001b[32m[09/09 02:41:02 d2.evaluation.evaluator]: \u001b[0mInference done 1576/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:05:11\n",
      "\u001b[32m[09/09 02:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 1581/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:05:05\n",
      "\u001b[32m[09/09 02:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 1586/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:05:00\n",
      "\u001b[32m[09/09 02:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 1591/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:04:55\n",
      "\u001b[32m[09/09 02:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 1596/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:04:49\n",
      "\u001b[32m[09/09 02:41:29 d2.evaluation.evaluator]: \u001b[0mInference done 1601/1866. Dataloading: 0.0003 s/iter. Inference: 0.9646 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:04:44\n",
      "\u001b[32m[09/09 02:41:34 d2.evaluation.evaluator]: \u001b[0mInference done 1606/1866. Dataloading: 0.0003 s/iter. Inference: 0.9645 s/iter. Eval: 0.1082 s/iter. Total: 1.0732 s/iter. ETA=0:04:39\n",
      "\u001b[32m[09/09 02:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 1611/1866. Dataloading: 0.0003 s/iter. Inference: 0.9645 s/iter. Eval: 0.1082 s/iter. Total: 1.0732 s/iter. ETA=0:04:33\n",
      "\u001b[32m[09/09 02:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 1616/1866. Dataloading: 0.0003 s/iter. Inference: 0.9645 s/iter. Eval: 0.1082 s/iter. Total: 1.0733 s/iter. ETA=0:04:28\n",
      "\u001b[32m[09/09 02:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 1621/1866. Dataloading: 0.0003 s/iter. Inference: 0.9644 s/iter. Eval: 0.1082 s/iter. Total: 1.0731 s/iter. ETA=0:04:22\n",
      "\u001b[32m[09/09 02:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 1626/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1082 s/iter. Total: 1.0730 s/iter. ETA=0:04:17\n",
      "\u001b[32m[09/09 02:42:01 d2.evaluation.evaluator]: \u001b[0mInference done 1631/1866. Dataloading: 0.0003 s/iter. Inference: 0.9643 s/iter. Eval: 0.1082 s/iter. Total: 1.0730 s/iter. ETA=0:04:12\n",
      "\u001b[32m[09/09 02:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 1636/1866. Dataloading: 0.0003 s/iter. Inference: 0.9642 s/iter. Eval: 0.1082 s/iter. Total: 1.0729 s/iter. ETA=0:04:06\n",
      "\u001b[32m[09/09 02:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 1641/1866. Dataloading: 0.0003 s/iter. Inference: 0.9641 s/iter. Eval: 0.1082 s/iter. Total: 1.0728 s/iter. ETA=0:04:01\n",
      "\u001b[32m[09/09 02:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 1646/1866. Dataloading: 0.0003 s/iter. Inference: 0.9640 s/iter. Eval: 0.1082 s/iter. Total: 1.0727 s/iter. ETA=0:03:55\n",
      "\u001b[32m[09/09 02:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 1651/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1082 s/iter. Total: 1.0726 s/iter. ETA=0:03:50\n",
      "\u001b[32m[09/09 02:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 1656/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1082 s/iter. Total: 1.0726 s/iter. ETA=0:03:45\n",
      "\u001b[32m[09/09 02:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 1661/1866. Dataloading: 0.0003 s/iter. Inference: 0.9639 s/iter. Eval: 0.1082 s/iter. Total: 1.0726 s/iter. ETA=0:03:39\n",
      "\u001b[32m[09/09 02:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 1666/1866. Dataloading: 0.0003 s/iter. Inference: 0.9638 s/iter. Eval: 0.1082 s/iter. Total: 1.0725 s/iter. ETA=0:03:34\n",
      "\u001b[32m[09/09 02:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 1671/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1082 s/iter. Total: 1.0724 s/iter. ETA=0:03:29\n",
      "\u001b[32m[09/09 02:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 1676/1866. Dataloading: 0.0003 s/iter. Inference: 0.9637 s/iter. Eval: 0.1082 s/iter. Total: 1.0724 s/iter. ETA=0:03:23\n",
      "\u001b[32m[09/09 02:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 1681/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1082 s/iter. Total: 1.0723 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/09 02:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 1686/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1081 s/iter. Total: 1.0723 s/iter. ETA=0:03:13\n",
      "\u001b[32m[09/09 02:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 1691/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1081 s/iter. Total: 1.0723 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/09 02:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 1696/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1081 s/iter. Total: 1.0723 s/iter. ETA=0:03:02\n",
      "\u001b[32m[09/09 02:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 1701/1866. Dataloading: 0.0003 s/iter. Inference: 0.9636 s/iter. Eval: 0.1081 s/iter. Total: 1.0722 s/iter. ETA=0:02:56\n",
      "\u001b[32m[09/09 02:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 1706/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1081 s/iter. Total: 1.0722 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/09 02:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 1711/1866. Dataloading: 0.0003 s/iter. Inference: 0.9635 s/iter. Eval: 0.1081 s/iter. Total: 1.0721 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/09 02:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 1716/1866. Dataloading: 0.0003 s/iter. Inference: 0.9634 s/iter. Eval: 0.1081 s/iter. Total: 1.0721 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/09 02:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 1721/1866. Dataloading: 0.0003 s/iter. Inference: 0.9634 s/iter. Eval: 0.1081 s/iter. Total: 1.0720 s/iter. ETA=0:02:35\n",
      "\u001b[32m[09/09 02:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 1726/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0720 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 02:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 1731/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0720 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/09 02:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 1736/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/09 02:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 1741/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/09 02:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 1746/1866. Dataloading: 0.0003 s/iter. Inference: 0.9632 s/iter. Eval: 0.1081 s/iter. Total: 1.0718 s/iter. ETA=0:02:08\n",
      "\u001b[32m[09/09 02:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 1751/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/09 02:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 1756/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/09 02:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 1761/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0720 s/iter. ETA=0:01:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 02:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 1766/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:47\n",
      "\u001b[32m[09/09 02:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 1771/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/09 02:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 1776/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:36\n",
      "\u001b[32m[09/09 02:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 1781/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/09 02:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 1786/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/09 02:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 1791/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0720 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/09 02:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 1796/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/09 02:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 1801/1866. Dataloading: 0.0003 s/iter. Inference: 0.9633 s/iter. Eval: 0.1081 s/iter. Total: 1.0719 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/09 02:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 1806/1866. Dataloading: 0.0003 s/iter. Inference: 0.9632 s/iter. Eval: 0.1080 s/iter. Total: 1.0718 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/09 02:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 1811/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0717 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/09 02:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 1816/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0717 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/09 02:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 1821/1866. Dataloading: 0.0003 s/iter. Inference: 0.9631 s/iter. Eval: 0.1080 s/iter. Total: 1.0716 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/09 02:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 1826/1866. Dataloading: 0.0003 s/iter. Inference: 0.9630 s/iter. Eval: 0.1080 s/iter. Total: 1.0715 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/09 02:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 1831/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0714 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/09 02:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 1836/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0713 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/09 02:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 1841/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1080 s/iter. Total: 1.0713 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/09 02:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 1846/1866. Dataloading: 0.0003 s/iter. Inference: 0.9626 s/iter. Eval: 0.1080 s/iter. Total: 1.0711 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/09 02:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 1851/1866. Dataloading: 0.0003 s/iter. Inference: 0.9627 s/iter. Eval: 0.1080 s/iter. Total: 1.0712 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/09 02:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 1856/1866. Dataloading: 0.0003 s/iter. Inference: 0.9629 s/iter. Eval: 0.1080 s/iter. Total: 1.0714 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/09 02:46:05 d2.evaluation.evaluator]: \u001b[0mInference done 1861/1866. Dataloading: 0.0003 s/iter. Inference: 0.9629 s/iter. Eval: 0.1080 s/iter. Total: 1.0713 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/09 02:46:10 d2.evaluation.evaluator]: \u001b[0mInference done 1866/1866. Dataloading: 0.0003 s/iter. Inference: 0.9628 s/iter. Eval: 0.1080 s/iter. Total: 1.0713 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/09 02:46:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:33:14.024615 (1.071480 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 02:46:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:29:51 (0.962758 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 02:46:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 02:46:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[09/09 02:46:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 02:46:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 02:46:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.60 seconds.\n",
      "\u001b[32m[09/09 02:46:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 02:46:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      "\u001b[32m[09/09 02:46:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.357 | 3.719  | 0.697  | 1.360 | 1.742 | 0.633 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.59s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 02:46:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[09/09 02:46:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.93 seconds.\n",
      "\u001b[32m[09/09 02:46:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 02:46:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.14 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      "\u001b[32m[09/09 02:46:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.105 | 3.256  | 0.473  | 0.558 | 2.031 | 0.941 |\n",
      "Model's configuration saved to model_config.yaml\n",
      "Test results:\n",
      "OrderedDict([('bbox', {'AP': 1.3572010356365924, 'AP50': 3.7185449429124215, 'AP75': 0.6967894832966256, 'APs': 1.3595819462173098, 'APm': 1.742351449086726, 'APl': 0.6327368878319725}), ('segm', {'AP': 1.1047249262136754, 'AP50': 3.256132333751401, 'AP75': 0.4726522074641624, 'APs': 0.5577756470261663, 'APm': 2.031154276972043, 'APl': 0.9414435413153812})])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.model_zoo import model_zoo\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Register your training dataset with Detectron2\n",
    "register_coco_instances(\"custom_dataset_train\", {}, \"train_output_coco_annotations.json\", \"train/images\")\n",
    "\n",
    "# Register your test dataset with Detectron2\n",
    "register_coco_instances(\"custom_dataset_test\", {}, \"test_output_coco_annotations.json\", \"test/images\")\n",
    "\n",
    "# Define metadata for your training dataset (class names)\n",
    "metadata_train = MetadataCatalog.get(\"custom_dataset_train\")\n",
    "\n",
    "# Define metadata for your test dataset (class names)\n",
    "metadata_test = MetadataCatalog.get(\"custom_dataset_test\")\n",
    "\n",
    "# Create a configuration\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Set your custom configuration options here, for example:\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"custom_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"custom_dataset_test\",)  # Include your test dataset\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 1111  # Increase the maximum number of iterations\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.DEVICE = 'cpu'  # Use 'cuda' if GPU is available\n",
    "\n",
    "# Instantiate a trainer\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Optionally, evaluate the model on the test set\n",
    "evaluator = COCOEvaluator(\"custom_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "test_loader = build_detection_test_loader(cfg, \"custom_dataset_test\")\n",
    "test_results = inference_on_dataset(trainer.model, test_loader, evaluator)\n",
    "\n",
    "# Save the model's configuration to a YAML file\n",
    "model_config_path = \"model_config.yaml\"\n",
    "with open(model_config_path, \"w\") as f:\n",
    "    f.write(cfg.dump())\n",
    "\n",
    "print(f\"Model's configuration saved to {model_config_path}\")\n",
    "\n",
    "# Print and visualize the test results\n",
    "print(\"Test results:\")\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2\n",
    "\n",
    "# Load the saved model weights and configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"model_config.yaml\")  # Replace with the path to your model's configuration file\n",
    "cfg.MODEL.WEIGHTS = \"output/model_final.pth\"  # Replace with the path to your saved model weights\n",
    "\n",
    "# Set the device to CPU\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "\n",
    "# Create a predictor using the loaded model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Get a random image from the \"train/images\" folder\n",
    "image_folder = 'train/images'  # Replace with the path to your image folder\n",
    "image_files = os.listdir(image_folder)\n",
    "random_image_file = random.choice(image_files)\n",
    "image_path = os.path.join(image_folder, random_image_file)\n",
    "\n",
    "# Read the random image\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get predictions on the image\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Filter predictions with confidence > 75%\n",
    "instances = outputs[\"instances\"]\n",
    "filtered_instances = instances[instances.scores > 0.75]\n",
    "\n",
    "# Visualize the original image with filtered predictions\n",
    "v = Visualizer(image, metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(filtered_instances.to(\"cpu\"))\n",
    "\n",
    "# Show the image with predictions\n",
    "cv2.imshow(\"Predictions\", out.get_image()[:, :, ::-1])\n",
    "\n",
    "# Construct the path to the corresponding mask image\n",
    "mask_folder = 'train/binned_targets'  # Replace with the path to your mask folder\n",
    "mask_file = os.path.join(mask_folder, os.path.splitext(random_image_file)[0] + '_target.png')\n",
    "\n",
    "# Read and show the mask image\n",
    "mask_image = cv2.imread(mask_file)\n",
    "cv2.imshow(\"Mask\", mask_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "# Close all OpenCV windows when any key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
